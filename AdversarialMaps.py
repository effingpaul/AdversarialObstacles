# Here we generate a map consiting obstacles conditioned on the start and goal position. They are generated by a MLP model.
# The RRT algorithm is used to find a path from start to end point. This marks the reward for the model.

import numpy as np
import matplotlib.pyplot as plt
import random
import torch
import torch.nn as nn
import torch.optim as optim


class MapGenerator:
    def __init__(self, map_size, num_obstacles):
        self.map_size = map_size
        self.num_obstacles = num_obstacles
        self.obstacles = []
        
        # init actor NN
        self.actor = nn.Sequential(
            nn.Linear(2, 32),
            nn.ReLU(),
            nn.Linear(32, 32),
            nn.ReLU(),
            nn.Linear(32, 4)
        )

        # init critic
        self.critic = nn.Sequential(
            nn.Linear(2, 32),
            nn.ReLU(),
            nn.Linear(32, 32),
            nn.ReLU(),
            nn.Linear(32, 1)
        )
        
        self.actor_optim = optim.Adam(self.actor.parameters(), lr=0.001)

    def train_actor(data):
        # the data here are tuples of (start, goal, obstacles, reward) where reward is the time RTT took to find a path. This policy should maximize said reward.



